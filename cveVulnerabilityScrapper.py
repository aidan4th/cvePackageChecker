#Guide to using cveVulnerabilityScrapper

# Make sure file being read is .ods



# Limitations
#
# Many versions apply to packages before. Such as "prior to 3.1.0". 
# So cveVulnerabilityScrapper reads the version number in the any version category.
# This leads to some problems where it will over pick certain versions that don't apply.
# These will appear in the * category

# If their are more than 50 vendors for a product and more than 50 vulnerabilities it will only read the first 50.
# I have never seen this before just thought I would mention.



#Here are the commands to install everythin.If using python make sure you install it to the
# 
# pip install beautifulsoup4
# pip install selenium
# pip install pandas
# pip install odfpy
#
# For selenium you also need to prepare firefox to be run by your computer
# You can use geckodriver for this. In order to install geckodriver you need cargo
#
# curl https://sh.rustup.rs -sSf | sh
# cargo install geckodriver
#
# Final note, the version of firefox cannot be the same one that comes with snap on ubuntu for all the linux users out their :)


try:
    import pandas as pd
except ImportError:
    print('cveVulnerabilityScrapper import pandas. Try making sure it is downloaded with pip install pandas')
    quit()
try:
    from bs4 import BeautifulSoup
except ImportError:
    print('cveVulnerabilityScrapper import bs4. Try making sure it is downloaded with pip install beautifulsoup4')
    quit()

try:
    from vendorNode import venNode, versionBugs, purifyTest
except ImportError:
    print('cveVulnerabilityScrapper couldnt find vendorNode. Try making sure it is downloaded and in the same directory')
    quit()
try: 
    from  selenium import webdriver
    from selenium.webdriver.common.by import By
    from selenium.webdriver.common.keys import Keys
except ImportError:
    print("""%s cveVulnerabilityScrapper couldnt find selenium.  pip install selenium
    For selenium you also need to prepare firefox to be run by your computer
    You can use geckodriver for this. In order to install geckodriver you need cargo
    curl https://sh.rustup.rs -sSf | sh
    Then install geckodriver with
    cargo install geckodriver""")
    quit()

import sys
import time
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('-i', type = str, default= "packageList", help = 'Input file name, defualt is packageList (no .csv)', dest='fileInputName')
parser.add_argument('-o', type = str, default= "packageList", help = 'Output file name, defualt is packageList (no .csv)', dest='fileOutPutName')
parser.add_argument('-fpath', type = str, default= "", help = 'Sometimes selenium driver needs path to firefox (recommend to not touch if unsure)', dest='fpath')
args = parser.parse_args()

fileInputName = args.fileInputName
fileOutPutName = args.fileOutPutName
fpath = args.fpath

print("\n[cveVulnerabilityScrapper by Aidan Forth]")

def main():
    try:
        workbook = pd.read_excel(fileInputName + ".ods", engine = "odf", sheet_name = 0)
    except ImportError as e:
        print("\n[Failed to read input] possibly because forgot pip install odfpy")
        quit()
    workbook, collectedDataFile, strL = workbook[["Package Name", "Version"]], [], ""

    driver = webdriver.Firefox(fpath)

    #This for loop goes through every row of the given spreadsheet
    for workingRow in range(0,len(workbook.index)):
        #Initializing Variables
        valuePackageName, versionNumber  = str(workbook["Package Name"].iat[workingRow]), str(workbook["Version"].iat[workingRow])
        if versionNumber.find('+') != -1: versionNumber = versionNumber.split('+')[0] #Cleans up version numbers. 
        dataToBeAddedToCollectedDataFile = [None] * 6
        dataToBeAddedToCollectedDataFile[0],dataToBeAddedToCollectedDataFile[1],dataToBeAddedToCollectedDataFile[2],dataToBeAddedToCollectedDataFile[3],dataToBeAddedToCollectedDataFile[4],dataToBeAddedToCollectedDataFile[5] = "Version " + str(versionNumber), "", "Version *","",0,""
        
        #Information for terminal
        sys.stdout.write("\r" + " "*len(strL))
        sys.stdout.flush()
        strL = "(" + str(workingRow) + "/" + str(len(workbook.index)) +") looking at [" + valuePackageName +"]"
        sys.stdout.write("\r"+strL)
        sys.stdout.flush()
        try:
            driver.get("https://www.cvedetails.com/product-search.php?vendor_id=0&search=" + valuePackageName)
            websiteContent = driver.page_source
            soup = BeautifulSoup(websiteContent, features="html.parser")


            #What this does is it goes to website searches based on product name then finds all the different
            #Vendors versions of those versions
            vendor = []
            for link in soup.find_all("a"):
                if (link.get("href")[0:8] == "/vendor/"):
                    v1 = venNode(link.get_text().lower(), link.get("href").split("/")[2], None, None)
                    vendor.append(v1)
            for link in soup.find_all("a"): #Could be combined into 1 for loop for time saving, but I am lazy and that is hard
                if (link.has_attr('href') & link.has_attr('title')):
                    if (link.get_text().lower() == valuePackageName and link.get("href")[0:8] != "/vendor/"):
                        for ven in vendor:
                            if (ven.id == link.get("href").split("vendor_id=")[1]):
                                ven.linkToV = link.get("href")
                                ven.idP = link.get("href").split("/")[2]

            
            
            
            #This goes through every vendor page that we just found
            for ven in vendor:


                countNumberOfLinks = 50 #Counts the number of version links in case we need to go to the next page
                pageNumber = 0
                while(countNumberOfLinks >= 50):
                    countNumberOfLinks = 0
                    pageNumber += 1

                    #Gets website html for the list of versions
                    if (ven.linkToV == None): break
                    driver.get("https://www.cvedetails.com/version-list/" +  ven.id + "/" +str(ven.idP)+ "/" + str(pageNumber)+ "/" +ven.linkToV.split("/")[3].split("?")[0])
                    websiteContent = driver.page_source
                    soup = BeautifulSoup(websiteContent, features="html.parser")


                    #This loop looks at every version
                    for link in soup.find_all("a"):
                        versionOfVulnerabilities = link.get("href")
                        
                        #Sees if the links are a version list
                        if (versionOfVulnerabilities[0:20] == "/vulnerability-list/"):
                            countNumberOfLinks += 1 #Increments by 1 to count if page max≈õ out at 50 and the second one should be reached



                            #This will run if the version equals the one we want, lots of string manipulation to find this out
                            if (versionOfVulnerabilities[::-1][5:].split("-")[0][::-1] == versionNumber):
                                
                                #Goes to vulnerability website, to get data
                                driver.get("https://www.cvedetails.com/" + link.get("href"))
                                websiteContent = driver.page_source
                                soupV = BeautifulSoup(websiteContent, features="html.parser")

                                #Reads through every vuklnerability
                                for tdTag in soupV.find_all("td"): #Will not include errors 50+
                                    if (tdTag.has_attr('class') & tdTag.has_attr('colspan')):
                                        if (tdTag.get('class')[0] == "cvesummarylong"):
                                            tvb = ven
                                            while(tvb.next != None):
                                                tvb = tvb.next
                                            tvb.next =  versionBugs(versionNumber, tdTag.get_text())
                            
                            
                            #This is the null version case, which means the vulnerabilities listed here apply to multiple versions
                            #The purfiyText trys to read this and guess if these versions apply to the version we inputted in the spread sheet
                            elif (versionOfVulnerabilities[::-1][5:][0:1] == "-"):
                                driver.get("https://www.cvedetails.com/" + link.get("href"))
                                websiteContent = driver.page_source
                                soupV = BeautifulSoup(websiteContent, features="html.parser")
                                for tdTag in soupV.find_all("td"): #Will not include errors 50+
                                    if (tdTag.has_attr('class') & tdTag.has_attr('colspan')):
                                        if (tdTag.get('class')[0] == "cvesummarylong"):
                                            tvb = ven
                                            while(tvb.next != None):
                                                tvb = tvb.next
                                            if (purifyTest(versionNumber, tdTag.get_text())): 
                                                tvb.next =  versionBugs("*", tdTag.get_text())   
                
                
                
                #So The program so fat has taken the list of things and put it into the vb function, now I need to add it to panda.
                # Then the first half should be done. Sorry if this is ugly, but it was the easist way to do it and it makes sense.
                tvb = ven
                while (tvb.next != None):
                    tvb = tvb.next
                    if (tvb.version == versionNumber):
                        dataToBeAddedToCollectedDataFile[4] += 1
                        dataToBeAddedToCollectedDataFile[1] = dataToBeAddedToCollectedDataFile[1] + "  [" + ven.vendor + "]"  + tvb.problem.strip()
                    else:
                        dataToBeAddedToCollectedDataFile[4] += 1
                        dataToBeAddedToCollectedDataFile[3] = dataToBeAddedToCollectedDataFile[3] + "  [" + ven.vendor + "] "  + tvb.problem.strip()
                dataToBeAddedToCollectedDataFile[5] = dataToBeAddedToCollectedDataFile[5]+ "[" +ven.vendor+"]"
            collectedDataFile.append(dataToBeAddedToCollectedDataFile)
        except Exception as e:
            print("[Failed] " + valuePackageName +" " + str(e))

    df = pd.DataFrame(collectedDataFile)
    df.columns = ["Version[V]","Vulnerabilities[V]","* Versions","Vulnerabilities[*]","Total Vulnerabilities", "Vendors"]
    workbook = workbook.join(df)
    workbook.to_csv(fileOutPutName + ".csv")
    driver.quit()
    print("\n[Finished]")
if __name__ == "__main__":
    main()